#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
finetune_tts.py
===============

Ð•Ð´Ð¸Ð½Ñ‹Ð¹ CLIâ€‘Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚ Ð´Ð»Ñ:
  â€¢ Ð¿Ð¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ¸ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ð° Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð° csv+wavs â†’ HuggingFace Arrow
  â€¢ Ñ‚Ð¾Ð½ÐºÐ¾Ð¹ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ (fineâ€‘tune) Ð¼Ð¾Ð´ÐµÐ»Ð¸ F5â€‘TTS

â–ª Ð—Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ðµ Ð±ÐµÐ· Ð°Ñ€Ð³ÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð² â€” ÑÐºÑ€Ð¸Ð¿Ñ‚ Ð·Ð°Ð´Ð°ÑÑ‚ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹ Ð¿Ð¾ÑˆÐ°Ð³Ð¾Ð²Ð¾.
â–ª ÐÐ°Ð¶Ð¼Ð¸Ñ‚Ðµ Enter, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¿Ñ€Ð¸Ð½ÑÑ‚ÑŒ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ (Ð² [ÐºÐ²Ð°Ð´Ñ€Ð°Ñ‚Ð½Ñ‹Ñ… ÑÐºÐ¾Ð±ÐºÐ°Ñ…]).
â–ª Ð”Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¸ `data_prepared/` Ð¸ `ckpts/` ÑÐ¾Ð·Ð´Ð°ÑŽÑ‚ÑÑ Ñ€ÑÐ´Ð¾Ð¼ Ñ ÑÑ‚Ð¸Ð¼ ÑÐºÑ€Ð¸Ð¿Ñ‚Ð¾Ð¼.

ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹ Ð·Ð°Ð¿ÑƒÑÐºÐ°
---------------
# ÐŸÐ¾Ð»Ð½Ð¾ÑÑ‚ÑŒÑŽ Ð¸Ð½Ñ‚ÐµÑ€Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¾ (prepare + train)
$ python finetune_tts.py

# Ð¢Ð¾Ð»ÑŒÐºÐ¾ Ð¿Ð¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ° Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ð°:
$ python finetune_tts.py prepare \
      --inp_dir /path/to/csv_wavs \
      --out_dir /path/to/data_prepared \
      --vocab_path /path/to/vocab.txt

# ÐŸÐ¾Ð»Ð½Ñ‹Ð¹ Ñ†Ð¸ÐºÐ» Ð±ÐµÐ· Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ¾Ð²:
$ python finetune_tts.py all \
      --inp_dir /path/to/csv_wavs \
      --vocab_path /path/to/vocab.txt \
      --ckpt /path/to/base_model.pt \
      --epochs 1 \
      --lr 1e-5
"""

from __future__ import annotations

import argparse
import concurrent.futures
import csv
import json
import multiprocessing
import os
import shutil
import signal
import subprocess
import sys
from contextlib import contextmanager
from pathlib import Path
from typing import List, Tuple

import torch
import torchaudio
from accelerate import Accelerator
from datasets import Dataset as HFDataset_
from datasets import load_from_disk
from datasets.arrow_writer import ArrowWriter
from f5_tts.model import CFM, DiT, Trainer
from f5_tts.model.dataset import CustomDataset
from f5_tts.model.utils import (
    convert_char_to_pinyin,
    get_tokenizer,
    list_str_to_idx,
)
from tqdm import tqdm

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. Ð‘Ð°Ð·Ð¾Ð²Ñ‹Ðµ ÐºÐ¾Ð½ÑÑ‚Ð°Ð½Ñ‚Ñ‹ Ð¸ Ð´ÐµÑ„Ð¾Ð»Ñ‚â€‘Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE_DIR = Path(__file__).resolve().parent
DEFAULT_PREP_DIR = BASE_DIR / "data_prepared"
DEFAULT_CKPT_DIR = BASE_DIR / "ckpts"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ (NCCL, PyTorch, torch / accelerate)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
os.environ["TORCH_NCCL_ENABLE_MONITORING"] = "0"
os.environ["TORCH_NCCL_HEARTBEAT_TIMEOUT_SEC"] = "1200"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3. Ð£Ñ‚Ð¸Ð»Ð¸Ñ‚Ñ‹ Ð¿Ð¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ¸ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ð° (csv+wavs â†’ arrow)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BATCH_SIZE = 100
MAX_WORKERS = max(1, multiprocessing.cpu_count() - 1)
THREAD_NAME_PREFIX = "AudioProcessor"
CHUNK_SIZE = 100
executor: concurrent.futures.ThreadPoolExecutor | None = None


@contextmanager
def graceful_exit():
    """ÐšÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ð¾Ðµ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ðµ Ð¿Ð¾ Ctrlâ€‘C / SIGTERM."""
    def _handler(signum, frame):
        print("\nâ›”  Interrupt received, cleaning upâ€¦")
        if executor is not None:
            executor.shutdown(wait=False, cancel_futures=True)
        sys.exit(1)

    signal.signal(signal.SIGINT, _handler)
    signal.signal(signal.SIGTERM, _handler)
    try:
        yield
    finally:
        if executor is not None:
            executor.shutdown(wait=False)


def is_csv_wavs_format(dataset_dir: os.PathLike) -> bool:
    p = Path(dataset_dir)
    return (p / "metadata.csv").is_file() and (p / "wavs").is_dir()


def get_audio_duration(path: str, timeout: int = 5) -> float:
    """Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° ffprobe (Ð±Ñ‹ÑÑ‚Ñ€Ð¾), fallback â€” torchaudio."""
    cmd = [
        "ffprobe",
        "-v", "error",
        "-show_entries", "format=duration",
        "-of", "default=noprint_wrappers=1:nokey=1",
        path,
    ]
    try:
        res = subprocess.run(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            check=True,
            timeout=timeout,
        )
        return float(res.stdout.strip())
    except Exception:
        audio, sr = torchaudio.load(path)
        return audio.shape[1] / sr


def read_audio_text_pairs(csv_file: os.PathLike) -> List[Tuple[str, str]]:
    root = Path(csv_file).parent
    pairs: List[Tuple[str, str]] = []
    with open(csv_file, newline="", encoding="utf-8-sig") as f:
        rdr = csv.reader(f, delimiter="|")
        next(rdr, None)  # Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº
        for row in rdr:
            if len(row) >= 2:
                fil_nm = row[0].strip()+".mp3"
                pairs.append((str(root / "wavs" / fil_nm), row[1].strip()))
    return pairs


def batch_convert_texts(
    texts: List[str], polyphone: bool = True, batch_size: int = BATCH_SIZE
) -> List[str]:
    out: List[str] = []
    for i in range(0, len(texts), batch_size):
        out.extend(
            convert_char_to_pinyin(texts[i : i + batch_size], polyphone=polyphone)
        )
    return out


def process_audio_file(audio_path: str, text: str, polyphone: bool = True):
    """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ (audio_path, converted_text, duration) Ð»Ð¸Ð±Ð¾ None Ð¿Ñ€Ð¸ Ð¾ÑˆÐ¸Ð±ÐºÐµ."""
    if not Path(audio_path).exists():
        return None
    try:
        dur = get_audio_duration(audio_path)
        if dur <= 0:
            raise ValueError("duration <= 0")
        return audio_path, text, dur
    except Exception:
        return None


def prepare_csv_wavs_dir(inp_dir, num_workers=None):
    global executor
    if not is_csv_wavs_format(inp_dir):
        raise ValueError(f"{inp_dir} is not in csv_wavs format")

    pairs = read_audio_text_pairs(Path(inp_dir) / "metadata.csv")
    total = len(pairs)
    workers = num_workers if num_workers else min(MAX_WORKERS, total)
    print(f"ðŸ›   Processing {total} files on {workers} threads")

    results = []
    with graceful_exit(), concurrent.futures.ThreadPoolExecutor(
        max_workers=workers, thread_name_prefix=THREAD_NAME_PREFIX
    ) as executor:
        futs = [executor.submit(process_audio_file, p, t) for p, t in pairs]
        for fut in tqdm(
            concurrent.futures.as_completed(futs), total=len(futs), desc="audio"
        ):
            r = fut.result()
            if r:
                results.append(r)

    if not results:
        raise RuntimeError("No valid audio processed!")

    raw_texts = [t for _, t, _ in results]
    converted = batch_convert_texts(raw_texts)

    entries, durations, vocab = [], [], set()
    for (audio, _t, dur), conv in zip(results, converted):
        entries.append({"audio_path": audio, "text": conv, "duration": dur})
        durations.append(dur)
        vocab.update(conv)

    return entries, durations, vocab


def save_prepared_dataset(
    out_dir,
    entries,
    durations,
    vocab_set,
    is_finetune: bool,
    vocab_path: str | None,
):
    out = Path(out_dir)
    out.mkdir(parents=True, exist_ok=True)
    print(f"ðŸ’¾ Saving dataset â†’ {out}")

    with ArrowWriter(path=str(out / "raw.arrow"), writer_batch_size=100) as w:
        for e in tqdm(entries, desc="arrow"):
            w.write(e)

    (out / "duration.json").write_text(
        json.dumps({"duration": durations}, ensure_ascii=False)
    )

    vocab_out = out / "vocab.txt"
    if is_finetune:
        if not vocab_path or not Path(vocab_path).is_file():
            raise FileNotFoundError("Pretrained vocab.txt required for finetune")
        shutil.copy2(vocab_path, vocab_out)
    else:
        with open(vocab_out, "w", encoding="utf-8") as f:
            for v in sorted(vocab_set):
                f.write(v + "\n")

    print(
        f"ðŸ“Š samples: {len(entries)} | vocab: {len(vocab_set)} | hours: {sum(durations)/3600:.2f}"
    )


def prepare_and_save_set(
    inp_dir,
    out_dir,
    vocab_path,
    is_finetune: bool = True,
    num_workers: int | None = None,
):
    entries, durs, vocab = prepare_csv_wavs_dir(inp_dir, num_workers)
    save_prepared_dataset(out_dir, entries, durs, vocab, is_finetune, vocab_path)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4. Fineâ€‘tune F5â€‘TTS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_finetune(
    prepared_dir,
    output_dir,
    vocab_path,
    ckpt_path,
    epochs: int,
    lr: float,
    batch_size_frames: int,
):
    accelerator = Accelerator(mixed_precision="fp16")
    print(f"âš¡  device: {accelerator.device}")

    # Tokenizer
    vocab_map, vocab_size = get_tokenizer(str(vocab_path), "custom")
    tokenizer_fn = lambda txts: list_str_to_idx(txts, vocab_map)  # noqa: E731
    if accelerator.is_main_process:
        print(f"Vocab size: {vocab_size}")

    # Model
    mel_args = dict(
        n_fft=1024,
        hop_length=256,
        win_length=1024,
        n_mel_channels=100,
        target_sample_rate=24000,
        mel_spec_type="vocos",
    )
    model = CFM(
        transformer=DiT(
            dim=1024,
            depth=22,
            heads=16,
            ff_mult=2,
            text_dim=512,
            conv_layers=4,
            text_num_embeds=vocab_size,
        ),
        mel_spec_kwargs=mel_args,
        vocab_char_map=vocab_map,
    )

    # Load checkpoint
    print("ðŸ”„ Loading base checkpointâ€¦")
    state = torch.load(ckpt_path, map_location="cpu")
    model.load_state_dict(state.get("model_state_dict", state), strict=False)

    # Dataset
    prepared_dir = Path(prepared_dir)
    try:
        ds_raw = load_from_disk(str(prepared_dir / "raw"))
    except Exception:
        ds_raw = HFDataset_.from_file(str(prepared_dir / "raw.arrow"))
    durations = json.loads((prepared_dir / "duration.json").read_text())["duration"]

    dataset = CustomDataset(
        ds_raw, durations=durations, preprocessed_mel=False, **mel_args
    )

    # Trainer
    trainer = Trainer(
        model=model,
        epochs=epochs,
        learning_rate=lr,
        num_warmup_updates=2000,
        save_per_updates=2000,
        keep_last_n_checkpoints=6,
        checkpoint_path=str(output_dir),
        batch_size_per_gpu=batch_size_frames,
        batch_size_type="frame",
        max_samples=64,
        grad_accumulation_steps=1,
        max_grad_norm=1,
        logger="tensorboard" if accelerator.is_main_process else None,
        wandb_project=prepared_dir.name if accelerator.is_main_process else None,
        wandb_run_name="finetune",
        last_per_updates=10000,
    )

    trainer.model = accelerator.prepare(trainer.model)

    if accelerator.is_main_process:
        print("ðŸš€ Starting fineâ€‘tuneâ€¦")
    trainer.train(dataset)
    if accelerator.is_main_process:
        print("âœ… Fineâ€‘tune complete.")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5. CLI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def build_parser():
    p = argparse.ArgumentParser(
        description="Prepare csv+wavs and fineâ€‘tune F5â€‘TTS",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
    sub = p.add_subparsers(dest="subcmd")

    # prepare
    sp = sub.add_parser("prepare", help="only prepare dataset")
    sp.add_argument("--inp_dir", help="csv+wavs dataset directory")
    sp.add_argument("--out_dir", default=str(DEFAULT_PREP_DIR))
    sp.add_argument(
        "--pretrain",
        action="store_true",
        help="set if this is NOT a finetune but fresh preâ€‘training",
    )
    sp.add_argument("--vocab_path", help="pretrained vocab.txt for finetune")
    sp.add_argument("--workers", type=int, help="threads for audio processing")

    # train
    st = sub.add_parser("train", help="only fineâ€‘tune")
    st.add_argument("--prepared_dir", default=str(DEFAULT_PREP_DIR))
    st.add_argument("--vocab_path")
    st.add_argument("--ckpt", help="base checkpoint .pt")
    st.add_argument("--output_ckpts", default=str(DEFAULT_CKPT_DIR))
    st.add_argument("--epochs", type=int, default=100)
    st.add_argument("--lr", type=float, default=1e-5)
    st.add_argument("--batch_size_frames", type=int, default=4000)

    # all
    sa = sub.add_parser("all", help="prepare + fineâ€‘tune")
    for a in sp._actions + st._actions:
        if a.dest not in {x.dest for x in sa._actions}:
            sa._add_action(a)

    return p


def interactive_prompt(args: argparse.Namespace):
    """Ð—Ð°Ð¿Ñ€Ð°ÑˆÐ¸Ð²Ð°ÐµÐ¼ Ð½ÐµÐ´Ð¾ÑÑ‚Ð°ÑŽÑ‰Ð¸Ðµ Ð°Ñ€Ð³ÑƒÐ¼ÐµÐ½Ñ‚Ñ‹."""
    print(
        "\nðŸ“  Ð¡ÐºÑ€Ð¸Ð¿Ñ‚ Ð²Ñ‹Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ Ð¿Ð¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÑƒ Ð¸/Ð¸Ð»Ð¸ fineâ€‘tune.\n"
        "âŽ  â€” Ð¿Ñ€Ð¸Ð½ÑÑ‚ÑŒ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ (Ð² [ÐºÐ²Ð°Ð´Ñ€Ð°Ñ‚Ð½Ñ‹Ñ… ÑÐºÐ¾Ð±ÐºÐ°Ñ…]).\n"
    )

    def ask(attr: str, prompt: str, default: str | None = None):
        val = getattr(args, attr, None)
        if not val:
            ans = input(f"{prompt}{f' [{default}]' if default else ''}: ").strip()
            setattr(args, attr, ans or default)

    if args.subcmd in ("prepare", "all"):
        ask("inp_dir", "ðŸ—‚  Path to csv+wavs dataset")
        ask("out_dir", "ðŸ“ Output dir for prepared dataset", str(DEFAULT_PREP_DIR))
        if not getattr(args, "pretrain", False):
            ask("vocab_path", "ðŸ“ƒ Path to pretrained vocab.txt")

    if args.subcmd in ("train", "all"):
        ask(
            "prepared_dir",
            "ðŸ—‚  Path to prepared dataset",
            str(getattr(args, "out_dir", DEFAULT_PREP_DIR)),
        )
        ask("ckpt", "ðŸ”‘ Pretrained checkpoint .pt")
        ask(
            "output_ckpts",
            "ðŸ“ Output dir for fineâ€‘tune ckpts",
            str(DEFAULT_CKPT_DIR),
        )
        ask(
            "vocab_path",
            "ðŸ“ƒ vocab.txt (tokenizer)",
            str(Path(args.prepared_dir) / "vocab.txt")
            if args.prepared_dir
            else None,
        )
        ask("epochs", "ðŸ”„ Epochs", "100")
        ask("lr", "ðŸ’¡ Learning rate", "1e-5")
        ask("batch_size_frames", "ðŸ“¦ Batch (frames)", "4000")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 6. main
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    parser = build_parser()
    ns = parser.parse_args()

    # ÐŸÐ¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ Ð²Ñ‹Ð¿Ð¾Ð»Ð½Ð¸Ð¼ Ð²ÑÑ‘ (prepare + train)
    if ns.subcmd is None:
        ns.subcmd = "all"

    # Ð“Ð°Ñ€Ð°Ð½Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ðµ Ð²ÑÐµÑ… Ð°Ñ‚Ñ€Ð¸Ð±ÑƒÑ‚Ð¾Ð²
    for k in [
        "inp_dir",
        "out_dir",
        "vocab_path",
        "workers",
        "pretrain",
        "prepared_dir",
        "ckpt",
        "output_ckpts",
        "epochs",
        "lr",
        "batch_size_frames",
    ]:
        if not hasattr(ns, k):
            setattr(ns, k, None)

    interactive_prompt(ns)

    # SHâ€‘prepare
    if ns.subcmd in ("prepare", "all"):
        prepare_and_save_set(
            inp_dir=ns.inp_dir,
            out_dir=ns.out_dir,
            vocab_path=ns.vocab_path,
            is_finetune=not ns.pretrain,
            num_workers=ns.workers,
        )

    # SHâ€‘train
    if ns.subcmd in ("train", "all"):
        run_finetune(
            prepared_dir=ns.prepared_dir or ns.out_dir,
            output_dir=ns.output_ckpts,
            vocab_path=ns.vocab_path
            or str(Path(ns.prepared_dir or ns.out_dir) / "vocab.txt"),
            ckpt_path=ns.ckpt,
            epochs=int(ns.epochs),
            lr=float(ns.lr),
            batch_size_frames=int(ns.batch_size_frames),
        )
